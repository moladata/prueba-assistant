# AI Research Assistant - Astron Agent Workflow

This open-source workflow for [Astron Agent](https://github.com/iflytek/astron-agent) transforms a simple topic into a comprehensive research report, complete with an executive summary. It's designed to automate the process of information gathering and synthesis, making it a powerful tool for students, analysts, and content creators.

This project was created as part of a sponsored video. You can watch the full tutorial and behind-the-scenes on [Your YouTube Channel Name](https://www.youtube.com/YOUR_CHANNEL_LINK).

![Workflow Demo](https://your-image-host.com/demo.gif)  <!-- It's highly recommended to add a GIF showing the workflow in action -->

## ‚ú® Features

- **Automated Research**: Generates a full report from a single topic.
- **Multi-Stage Processing**: Uses a 4-step LLM chain for deep analysis and structured output.
- **Model Agnostic**: Works with any OpenAI-compatible LLM (tested with Groq Llama 3.1 and Google Gemini).
- **Easy to Use**: Import and run the workflow in minutes.
- **Fully Open Source**: Free to use, modify, and distribute.

## ‚öôÔ∏è How It Works

The workflow is a sequential chain of four Large Language Model (LLM) nodes:

1.  **Generate Questions**: Takes the user's topic and generates 5-7 key research questions.
2.  **Deep Analysis**: Answers each question in detail, providing a comprehensive analysis.
3.  **Generate Report**: Structures the analysis into a professional Markdown report with a title, table of contents, and organized sections.
4.  **Executive Summary**: Creates a concise, 200-word summary of the final report, highlighting key findings and actions.

## üöÄ Getting Started

### Prerequisites

1.  **Docker** and **Docker Compose** installed on your machine.
2.  An **OpenAI-compatible API Key** from a provider like:
    - [Groq](https://console.groq.com/) (Fast & Free)
    - [Google AI Studio](https://aistudio.google.com/apikey) (Free Tier)

### 1. Install Astron Agent

Clone the official Astron Agent repository and run it using Docker:

```bash
# Clone the repository
git clone https://github.com/iflytek/astron-agent.git

# Navigate to the docker directory
cd astron-agent/docker/astronAgent

# Create the .env file from the example
# On Windows (CMD):
copy .env.example .env
# On Linux/macOS:
cp .env.example .env

# Start the services
docker compose -f docker-compose-with-auth.yaml up -d
```

Wait 3-5 minutes for all services to start. Access the interface at `http://localhost/`.

### 2. Configure the LLM

- Log in with `admin` / `123`.
- Go to **Model Management** > **+ Create Model**.
- Select **Add Third Party Model**.
- Fill in the details for your chosen LLM provider (e.g., Groq):
  - **Model Name**: `Groq-Llama`
  - **model**: `llama-3.1-8b-instant`
  - **API Endpoint**: `https://api.groq.com/openai/v1`
  - **API Key**: Your Groq API Key
- Click **Submit**.

### 3. Import and Run the Workflow

1.  Go to **My Agents** > **+ Create**.
2.  Click the **Import** button (top right) and upload the `AI-Research-Assistant.yml` file from this repository.
3.  The workflow will be imported. Click on it to open the orchestration view.
4.  Click **Debug** (top right).
5.  Enter a topic you want to research (e.g., "The future of renewable energy").
6.  Click **Run** and watch the magic happen!

## üìÑ Sample Output

Here is an [example of a report generated by this workflow](examples/sample-output.md).

## ü§ù Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the [issues page](https://github.com/YOUR_USERNAME/ai-research-assistant/issues).

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

*This project is for educational and demonstration purposes as part of a sponsored collaboration with iFlytek's Astron Agent.*
